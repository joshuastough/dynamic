{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A motion-seg dataset, for Edward's [MotionSeg](https://gitlab.com/edward_chen/joint_segmentation_motion_estimation) code.\n",
    "Stough 7/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import echonet\n",
    "import os\n",
    "from argparse import Namespace\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import interpolate\n",
    "from queue import SimpleQueue as squeue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 15.16it/s]\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(modelname=\"deeplabv3_resnet50\",\n",
    "                 pretrained=False,\n",
    "                 clip_length=10,\n",
    "                 device=\"cuda\",\n",
    "                 output=None,\n",
    "                 num_workers=6,\n",
    "                 image_size=[256,256],\n",
    "                 norm=True,\n",
    "                 all_clips=True)\n",
    "\n",
    "mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(split=\"train\"))\n",
    "\n",
    "output = os.path.join(\"output\", \"segmentation\", \"{}_{}\".format(args.modelname, \"pretrained\" if args.pretrained else \"random\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## We need to define some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New EDESpairs: Start at every systolic, step backwards to the \n",
    "# nearest diastolic, and call that a clip. Then for the next one \n",
    "# make sure we don't pass the previous systole while stepping back.\n",
    "\n",
    "def EDESpairs(diastole, systole):\n",
    "    dframes = np.sort(np.array(diastole))\n",
    "    sframes = np.sort(np.array(systole))\n",
    "    clips = []\n",
    "    \n",
    "    inds = np.searchsorted(diastole, systole, side='left')\n",
    "    for i, sf in enumerate(systole):\n",
    "        if inds[i] == 0: # no prior diastolic frames for this sf\n",
    "            continue\n",
    "        best_df = diastole[inds[i]-1] # diastole frame nearest this sf.\n",
    "        if len(clips) == 0 or best_df != clips[-1][0]:\n",
    "            clips.append((best_df, sf))\n",
    "            \n",
    "    return clips\n",
    "\n",
    "\n",
    "\n",
    "# # Given iterable lists of frame numbers. The first pair \n",
    "# # is the first diastole and the first larger systole. \n",
    "# # EDESpairs({38, 73, 96}, {19, 53, 87}) \n",
    "# #        => [(38, 53), (73, 87)]\n",
    "# def EDESpairs(diastole, systole):\n",
    "#     ret = []\n",
    "#     dq = squeue()\n",
    "#     sq = squeue()\n",
    "#     [dq.put(x) for x in sorted(diastole)];\n",
    "#     [sq.put(x) for x in sorted(systole)];\n",
    "    \n",
    "#     while not dq.empty():\n",
    "#         dframe = dq.get()\n",
    "#         while not sq.empty():\n",
    "#             t = sq.get()\n",
    "#             if t > dframe:\n",
    "#                 ret.append((dframe, t))\n",
    "#                 break\n",
    "#     return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamusizeVideo(object):\n",
    "    def __init__(self, im_size=[256,256], clip_length=args.clip_length, norm=True):\n",
    "        self.im_size = im_size\n",
    "        self.clip_length = clip_length\n",
    "        self.norm = norm\n",
    "        \n",
    "    def _norm(self, video):\n",
    "        # expecting f x h x w \n",
    "        # make 0-1, but in tensors:\n",
    "        # https://discuss.pytorch.org/t/how-to-efficiently-normalize-a-batch-of-tensor-to-0-1/65122/4\n",
    "        # print(f'_norm sees videos shape {videos.shape}\\n')\n",
    "        AA = video.clone()\n",
    "        AA = AA.view(self.clip_length, -1) # each frame is vectorized (256x256 -> 65536)\n",
    "        AA -= AA.min(1, keepdim=True)[0] # subtract frame min from each frame\n",
    "        AA /= AA.max(1, keepdim=True)[0] # divide by frame max for each frame\n",
    "        AA = 2.0*AA.view(video.shape)-1.0 # reconstitute the frames (65536 -> 256x256)\n",
    "        return AA\n",
    "    \n",
    "    def _rgb2gray(self, video):\n",
    "        # Takes the 5D batch/c/f/h/w and collapses c to size 1 by combining the r,g,b components.\n",
    "        # 0.2989 * R + 0.5870 * G + 0.1140 * B \n",
    "        return torch.mul(video, torch.tensor([.2989, .5870, .1140])[:, None, None, None]).sum(0, keepdim=True)\n",
    "        \n",
    "    '''\n",
    "    Object call: Should take video batches and convert to\n",
    "    CAMUS-acceptable images (in [0-1], and 256x256 single channel):\n",
    "    video is c(3) x f x h x w. \n",
    "    '''\n",
    "    def __call__(self, video):\n",
    "        out_video = self._rgb2gray(torch.tensor(video)) # -> 1 x f x h x w\n",
    "        out_video = interpolate(out_video.unsqueeze(0), size=[self.clip_length] + self.im_size, \n",
    "                                 mode='trilinear', align_corners=False) # 1 x clip_length x im_size\n",
    "        \n",
    "        out_video = self._norm(out_video.squeeze()) # -> norm each frame to [0,1]\n",
    "        \n",
    "        return out_video.unsqueeze(0) # -> 1 x clip_length x im_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanfordMotionDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 modelname = args.modelname,\n",
    "                 pretrained = args.pretrained,\n",
    "                 image_size=args.image_size, \n",
    "                 clip_length=args.clip_length, \n",
    "                 norm=args.norm,\n",
    "                 all_clips=args.all_clips,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        \n",
    "        mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(split=\"train\"))\n",
    "        self.output = os.path.join(\"output\", \"segmentation\", \"{}_{}\".format(modelname, \n",
    "                                                                            \"pretrained\" if pretrained else \"random\"))\n",
    "        self.all_clips = all_clips\n",
    "        self.image_size = image_size\n",
    "        self.clip_length = clip_length\n",
    "        self.norm = norm\n",
    "        # Need filename for saving, and human-selected frames to annotate\n",
    "        self.stanford = echonet.datasets.Echo(split=\"test\",\n",
    "                                              target_type=[\"Filename\", \"EF\", \"EDV\", \"ESV\", \\\n",
    "                                                           \"LargeIndex\", \"SmallIndex\", \\\n",
    "                                                           \"LargeFrame\", \"SmallFrame\", \\\n",
    "                                                           \"LargeTrace\", \"SmallTrace\"],  \n",
    "                                              mean=mean, std=std,  # Normalization\n",
    "                                              length=None, max_length=None, period=1  # Take all frames\n",
    "                                             )\n",
    "        self.camusizer = CamusizeVideo(im_size=self.image_size, \n",
    "                                       clip_length=self.clip_length, \n",
    "                                       norm=self.norm\n",
    "                                      )\n",
    "        self.sizes = pd.read_csv(os.path.join(self.output, \"size.csv\"))\n",
    "        self.ids = pd.unique(self.sizes.Filename)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "        \n",
    "    '''\n",
    "    Next try at finding video clips. \n",
    "    '''\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the appropriate info from the Stanford dataset\n",
    "        video, (filename, ef, edv, esv, l_index, s_index, l_frame, s_frame, l_trace, s_trace) = self.stanford[idx]\n",
    "        \n",
    "        # Now get the clip points for this video using the already recorded sizes.\n",
    "        idx_sizes = self.sizes.loc[self.sizes.Filename == self.ids[idx]]\n",
    "\n",
    "        size = idx_sizes.Size.values\n",
    "        _05cut, _85cut, _95cut = np.percentile(size, [5, 85, 95]) \n",
    "\n",
    "\n",
    "        trim_min = _05cut\n",
    "        trim_max = _95cut\n",
    "        trim_range = trim_max - trim_min\n",
    "        systole = find_peaks(-size, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "        diastole = find_peaks(size, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "\n",
    "        # keep only real diastoles..\n",
    "        diastole = [x for x in diastole if size[x] >= _85cut]\n",
    "        # Add first frame\n",
    "        if np.mean(size[:3]) >= _85cut:\n",
    "            diastole = [0] + diastole\n",
    "        diastole = np.array(diastole)\n",
    "\n",
    "        clip_pairs = EDESpairs(diastole, systole)\n",
    "        \n",
    "        #return clip_pairs\n",
    "        \n",
    "#         assert len(clip_pairs) > 0, f'StanfordMotionDataset clips issue: ' \\\n",
    "#                                     f'Video {self.ids[idx]} had diastole {diastole} and systole {systole}.\\n'\n",
    "        \n",
    "        videoclips = torch.tensor([])\n",
    "        for dframe, sframe in clip_pairs:\n",
    "            videoclips = torch.cat((videoclips,\n",
    "                                   self.camusizer(video[:,dframe:sframe,...])), 0)\n",
    "            if not self.all_clips:\n",
    "                return videoclips, clip_pairs, video, filename, large_index, small_index, ef, edv, esv\n",
    "        return videoclips, clip_pairs, video, filename, ef, edv, esv, l_index, s_index, l_frame, s_frame, l_trace, s_trace\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "#         # Get the appropriate info from the Stanford dataset\n",
    "#         video, (filename, ef, edv, esv, l_index, s_index, l_frame, s_frame, l_trace, s_trace) = self.stanford[idx]\n",
    "        \n",
    "#         # Now get the clip points for this video using the already recorded sizes.\n",
    "#         idx_sizes = self.sizes.loc[self.sizes.Filename == self.ids[idx]]\n",
    "        \n",
    "#         size = idx_sizes.Size.values\n",
    "#         trim_min = sorted(size)[round(len(size) ** 0.05)]\n",
    "#         trim_max = sorted(size)[round(len(size) ** 0.95)]\n",
    "#         trim_range = trim_max - trim_min\n",
    "#         systole = set(find_peaks(-size, distance=20, prominence=(0.50 * trim_range))[0])\n",
    "#         diastole = set(find_peaks(size, distance=20, prominence=(0.50 * trim_range))[0])\n",
    "        \n",
    "#         clip_pairs = EDESpairs(diastole, systole)\n",
    "        \n",
    "#         assert len(clip_pairs) > 0, f'StanfordMotionDataset clips issue: ' \\\n",
    "#                                     f'Video {self.ids[idx]} had diastole {diastole} and systole {systole}.\\n'\n",
    "        \n",
    "#         videoclips = torch.tensor([])\n",
    "#         for dframe, sframe in clip_pairs:\n",
    "#             videoclips = torch.cat((videoclips,\n",
    "#                                    self.camusizer(video[:,dframe:sframe,...])), 0)\n",
    "#             if not self.all_clips:\n",
    "#                 return videoclips, clip_pairs, video, filename, large_index, small_index, ef, edv, esv\n",
    "#         return videoclips, clip_pairs, video, filename, ef, edv, esv, l_index, s_index, l_frame, s_frame, l_trace, s_trace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Testing our Stanford ED/ES clip dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 14.37it/s]\n"
     ]
    }
   ],
   "source": [
    "motionSet = StanfordMotionDataset(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoclips, clip_pairs, video, filename, ef, edv, esv, \\\n",
    "l_index, s_index, l_frame, s_frame, l_trace, s_trace = motionSet[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95: 0X1ACB73BE8C1F2C0C.avi\n",
      "390: 0X350E5D4955052AFA.avi\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(motionSet)):\n",
    "    videoclips, clip_pairs, video, filename, ef, edv, esv, \\\n",
    "        l_index, s_index, l_frame, s_frame, l_trace, s_trace = motionSet[i]\n",
    "    if len(clip_pairs) == 0:\n",
    "        print(f'{i}: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Some looking into problem cases\n",
    "that maybe don't have any systoles etc.\n",
    "\n",
    "```\n",
    "0X5F40FC2C2367EA92.avi (one systole, no diastole)\n",
    "0X47DBEA2F11240016.avi (one systole, no diastole)\n",
    "0X350E5D4955052AFA.avi (no systole & no diastole)\n",
    "For the four videos below, each video has one systole frame and diastole frame, but systole frame comes before the diastole frame. Thus, the one clip of the video is from ES-ED.\n",
    "0X1ACB73BE8C1F2C0C.avi\n",
    "0X7DA74EAC9DFC2D5B.avi\n",
    "0X7F058A3503090EC8.avi\n",
    "0XEC340BEA3298AE3.avi\n",
    "\n",
    "\n",
    "Edward pointed to these as cases that we do particularly poorly on. Often\n",
    "the answers don't look incredibly bad, but still the numbers are way off. \n",
    "The first one we get an awful answer, but also the clip itself doesn't look \n",
    "ED-ES\n",
    "812  298*  685  1050  987  916*  511  772*  254*  1053  222*  180*  211*  440  819*\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoclips, clip_pairs, video, filename, ef, edv, esv, \\\n",
    "l_index, s_index, l_frame, s_frame, l_trace, s_trace = motionSet[812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0X5FE2CC293BF88CCD.avi'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the clip points for this video using the already recorded sizes.\n",
    "idx_sizes = motionSet.sizes.loc[motionSet.sizes.Filename == motionSet.ids[812]]\n",
    "\n",
    "size = idx_sizes.Size.values\n",
    "_05cut, _85cut, _95cut = np.percentile(size, [5, 85, 95]) \n",
    "\n",
    "\n",
    "trim_min = _05cut\n",
    "trim_max = _95cut\n",
    "trim_range = trim_max - trim_min\n",
    "systole = find_peaks(-size, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "diastole = find_peaks(size, distance=20, prominence=(0.50 * trim_range))[0]\n",
    "\n",
    "# keep only real diastoles..\n",
    "diastole = [x for x in diastole if size[x] >= _85cut]\n",
    "# Add first frame\n",
    "if np.mean(size[:3]) >= _85cut:\n",
    "    diastole = [0] + diastole\n",
    "diastole = np.array(diastole)\n",
    "\n",
    "clip_pairs = EDESpairs(diastole, systole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 24),\n",
       " (58, 78),\n",
       " (117, 140),\n",
       " (174, 197),\n",
       " (234, 256),\n",
       " (290, 314),\n",
       " (346, 359),\n",
       " (379, 389),\n",
       " (407, 417),\n",
       " (433, 447),\n",
       " (466, 475)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_index # Diastolic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(motionSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867d67453a874ae883e8fe633edcbab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8a1c70fad0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "plt.scatter(np.arange(len(size)), size, alpha=.6)\n",
    "plt.scatter(diastole, size[diastole], s=30, c='k')\n",
    "plt.scatter(systole, size[systole], s=30, c='k')\n",
    "clip_eds = [x for x,y in clip_pairs]\n",
    "clip_ess = [y for x,y in clip_pairs]\n",
    "plt.scatter(clip_eds, size[clip_eds], s=80, c='y')\n",
    "plt.scatter(clip_ess, size[clip_ess], s=80, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(size, bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "vid = echonet.utils.makeVideo(video[0,...], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_index, s_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lf = l_frame - l_frame.min()\n",
    "lf /= lf.max()\n",
    "sf = s_frame - s_frame.min()\n",
    "sf /= sf.max()\n",
    "plt.imshow(sf.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "ax[0].imshow(lf[0], cmap='gray')\n",
    "ax[0].imshow(l_trace==1, alpha=.3)\n",
    "ax[0].set_title('large frame')\n",
    "ax[1].imshow(sf[0], cmap='gray')\n",
    "ax[1].imshow(s_trace==1, alpha=.3)\n",
    "ax[1].set_title('small frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(video[0, 60,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
